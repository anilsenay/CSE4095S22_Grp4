{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d3c077-d38c-4646-ad4a-4c330c94942e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6c41d2-741e-4346-81b1-0beac9a05d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f15d46-c671-4b7d-afc4-71e471c3488b",
   "metadata": {},
   "source": [
    "# readJson function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbbf107f-90da-4e0a-ba4a-08a760f90a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJson(fileName):\n",
    "    f = open(file, \"r\", encoding='utf-8')\n",
    "    jsonData = json.load(f)\n",
    "    words = \"\"\n",
    "    for _, value in jsonData.items():\n",
    "        words = words + value\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fdb69-c4c6-437d-9975-535e029c9e09",
   "metadata": {},
   "source": [
    "# Find ngrams with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6e9e1e-2d04-409b-8c89-96a312e34917",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"testDatasets/*.json\"\n",
    "files = glob.glob(path)\n",
    "\n",
    "words = \"\"\n",
    "\n",
    "for file in files:\n",
    "    jsonWords = readJson(file)\n",
    "    words = words + jsonWords\n",
    "    \n",
    "tokenizedWords = [word.lower() for word in words.split() if len(word) > 1]\n",
    "\n",
    "ngramList = [\n",
    "    {\"n\": 1, \"prefix\": \"unigram\"},\n",
    "    {\"n\": 2, \"prefix\": \"bigram\"},\n",
    "    {\"n\": 3, \"prefix\": \"trigram\"}\n",
    "]\n",
    "\n",
    "for ngram in ngramList:\n",
    "    n = ngrams(tokenizedWords, ngram['n'])\n",
    "    nFreq = collections.Counter(n)\n",
    "    df = pd.DataFrame(nFreq.most_common(None), columns = ['Words', 'Frequency'])\n",
    "    df = df.sort_values(by='Frequency', ascending=False)\n",
    "    p = './outputs/' + ngram['prefix'] + '-with-stopwords.csv'\n",
    "    df.to_csv(p, index = True, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b69931-3969-4821-999f-bd334ba1aff7",
   "metadata": {},
   "source": [
    "# Read stopwords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3333e55-266f-4243-9c9b-b1799f4aba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"stopwords.txt\", \"r\", newline='', encoding='utf-8')\n",
    "result = file.read()\n",
    "stopwords = word_tokenize(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13681e-c136-45b6-95e0-ff593b6998f2",
   "metadata": {},
   "source": [
    "# Find ngrams without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b85d00-0413-42f7-afa2-546f9e1d4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"testDatasets/*.json\"\n",
    "files = glob.glob(path)\n",
    "\n",
    "words = \"\"\n",
    "\n",
    "for file in files:\n",
    "    jsonWords = readJson(file)\n",
    "    words = words + jsonWords\n",
    "    \n",
    "tokenizedWords = [word.lower() for word in words.split() if word.lower() not in stopwords and len(word) > 1]\n",
    "\n",
    "ngramList = [\n",
    "    {\"n\": 1, \"prefix\": \"unigram\"},\n",
    "    {\"n\": 2, \"prefix\": \"bigram\"},\n",
    "    {\"n\": 3, \"prefix\": \"trigram\"}\n",
    "]\n",
    "\n",
    "for ngram in ngramList:\n",
    "    n = ngrams(tokenizedWords, ngram['n'])\n",
    "    nFreq = collections.Counter(n)\n",
    "    df = pd.DataFrame(nFreq.most_common(None), columns = ['Words', 'Frequency'])\n",
    "    df = df.sort_values(by='Frequency', ascending=False)\n",
    "    p = './outputs/' + ngram['prefix'] + '-without-stopwords.csv'\n",
    "    df.to_csv(p, index = True, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9393c74-a680-4bf6-ba49-2b8a92471a8c",
   "metadata": {},
   "source": [
    "# Print filtered tokens to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17bf51f6-921f-4e7f-9703-b3c490ba5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./filtered-tokens.txt','a+', encoding='utf-8')\n",
    "for idx in tokenizedWords:\n",
    "    file.write(\" \"+idx.lower())\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc2684-4dec-46a4-bf7c-ead4386ab156",
   "metadata": {},
   "source": [
    "# Find collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653c5591-3610-4a0b-9a71-a22ddf9431b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./filtered-tokens.txt\", \"r\", newline='', encoding='utf-8')\n",
    "result = file.read()\n",
    "\n",
    "tokenized = [idx.lower() for idx in result.split()]\n",
    "\n",
    "bigrams = nltk.collocations.BigramAssocMeasures()\n",
    "trigrams = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "bigramFinder = nltk.collocations.BigramCollocationFinder.from_words(tokenized)\n",
    "trigramFinder = nltk.collocations.TrigramCollocationFinder.from_words(tokenized)\n",
    "\n",
    "bigramFinder.apply_freq_filter(20)\n",
    "trigramFinder.apply_freq_filter(20)\n",
    "\n",
    "bigram_freq = bigramFinder.ngram_fd.items()\n",
    "bigramFreqTable = pd.DataFrame(list(bigram_freq), columns=['Bigram','Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "bigramFreqTable.to_csv('./ngrams/bigrams.csv', index = False, header=True)\n",
    "\n",
    "trigram_freq = trigramFinder.ngram_fd.items()\n",
    "trigramFreqTable = pd.DataFrame(list(trigram_freq), columns=['Trigram','Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "trigramFreqTable.to_csv('./ngrams/trigrams.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfbece-ddf2-4a7f-9286-d37f6dc9914e",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad065ee-c211-47d8-855b-1ddf1435975e",
   "metadata": {},
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4af2bc4-801f-48c9-8690-a6642576225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramPMITable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.pmi)), columns=['bigram','PMI']).sort_values(by='PMI', ascending=False)\n",
    "bigramPMITable.to_csv('./methods/bigram/bigramPMITable.csv', index = False, header=True)\n",
    "\n",
    "trigramPMITable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.pmi)), columns=['trigram','PMI']).sort_values(by='PMI', ascending=False)\n",
    "trigramPMITable.to_csv('./methods/trigram/trigramPMITable.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a447975-cc84-409c-9632-ed7a9bfbdd19",
   "metadata": {},
   "source": [
    "## T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46a44abf-b6b1-44f4-b21e-ad1bb796aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramTtable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.student_t)), columns=['bigram','t']).sort_values(by='t', ascending=False)\n",
    "bigramTtable.to_csv('./methods/bigram/bigramTtable.csv', index = False, header=True)\n",
    "\n",
    "trigramTtable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.student_t)), columns=['trigram','t']).sort_values(by='t', ascending=False)\n",
    "trigramTtable.to_csv('./methods/trigram/trigramTtable.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b443a0a-aa3b-4ced-aba6-d5995433fe64",
   "metadata": {},
   "source": [
    "## Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5281da05-f39a-4838-beb9-3f47a872a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramChiTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.chi_sq)), columns=['bigram','chi-sq']).sort_values(by='chi-sq', ascending=False)\n",
    "bigramChiTable.to_csv('./methods/bigram/bigramChiTable.csv', index = False, header=True)\n",
    "\n",
    "trigramChiTable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.chi_sq)), columns=['trigram','chi-sq']).sort_values(by='chi-sq', ascending=False)\n",
    "trigramChiTable.to_csv('./methods/trigram/trigramChiTable.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6cd67-564d-4f23-9373-d24983223d82",
   "metadata": {},
   "source": [
    "## Raw Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e06a21-9cd8-4a27-b8f9-9e43a83b5e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramRawFreqTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.raw_freq)), columns=['bigram','raw_freq']).sort_values(by='raw_freq', ascending=False)\n",
    "bigramRawFreqTable.to_csv('./methods/bigram/bigramRawFreqTable.csv', index = False, header=True)\n",
    "\n",
    "trigramRawFreqTable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.raw_freq)), columns=['trigram','raw_freq']).sort_values(by='raw_freq', ascending=False)\n",
    "trigramRawFreqTable.to_csv('./methods/trigram/trigramRawFreqTable.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ce2bd-3691-44ae-8515-f700ab953b5c",
   "metadata": {},
   "source": [
    "## Poisson Stirling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076b109e-b8af-413f-ac64-22b578797352",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramPoissonTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.poisson_stirling)), columns=['bigram','poisson_stirling']).sort_values(by='poisson_stirling', ascending=False)\n",
    "bigramPoissonTable.to_csv('./methods/bigram/bigramPoissonTable.csv', index = False, header=True)\n",
    "\n",
    "trigramPoissonTable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.poisson_stirling)), columns=['trigram','poisson_stirling']).sort_values(by='poisson_stirling', ascending=False)\n",
    "trigramPoissonTable.to_csv('./methods/trigram/trigramPoissonTable.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b15f3-ec3e-4d22-aee4-053947151941",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Likelihood Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b96b58e6-b512-4ad8-9a1a-ed754f1aa4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramLikelihoodTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.likelihood_ratio)), columns=['bigram','likelihood_ratio']).sort_values(by='likelihood_ratio', ascending=False)\n",
    "bigramLikelihoodTable.to_csv('./methods/bigram/bigramLikelihoodTable.csv', index = False, header=True)\n",
    "\n",
    "trigramLikelihoodTable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.likelihood_ratio)), columns=['trigram','likelihood_ratio']).sort_values(by='likelihood_ratio', ascending=False)\n",
    "trigramLikelihoodTable.to_csv('./methods/trigram/trigramLikelihoodTable.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2bc99-bd03-4cf6-8815-faed45a70fbb",
   "metadata": {},
   "source": [
    "## Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aeb6b14-590a-4926-a8a6-40d3d16781e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramJaccardTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.jaccard)), columns=['bigram','jaccard']).sort_values(by='jaccard', ascending=False)\n",
    "bigramJaccardTable.to_csv('./methods/bigram/bigramJaccardTable.csv', index = False, header=True)\n",
    "\n",
    "trigramJaccardTable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.jaccard)), columns=['trigram','jaccard']).sort_values(by='jaccard', ascending=False)\n",
    "trigramJaccardTable.to_csv('./methods/trigram/trigramJaccardTable.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb408d-7554-4106-a476-f779487f76f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108dd9fd-5494-4100-924b-770f33cfefd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece3a4f-0a76-4787-a566-f05686d8041f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
