{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "27cb0d22-f68c-4d89-9426-0cb0ef5ad86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,re, os, glob, json, string, pprint\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from snowballstemmer import TurkishStemmer \n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5c0d7-a4df-4033-83a1-e77867bcd1b0",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "60d29c8d-3ea1-468a-89d7-b36633bf0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_size_threshold = 100\n",
    "similarity_ratio = 0.70\n",
    "path = \"datasets/*.json\"\n",
    "#path = \"C://Users/onkol/Desktop/2021-01-20220322T055600Z-001/2021-01/*.json\" \n",
    "create_data_json = False\n",
    "enable_preprocessing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8de2db-1211-4d1e-aabc-90982ab661de",
   "metadata": {},
   "source": [
    "## Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6ff48246-8214-4ed5-9fcb-29becb34d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27851\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(path)\n",
    "\n",
    "json_arr = []\n",
    "for file in files:\n",
    "    f = open(file, \"r\", encoding='utf-8')\n",
    "    jsonData = json.loads(f.read())\n",
    "    json_arr.append(jsonData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59b8de-799b-4a9e-9843-d37938bf183d",
   "metadata": {},
   "source": [
    "## Create labels from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8988295e-bd09-43d4-ac70-ce241b775dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not create_data_json):\n",
    "    raise Exception(\"NOT ERROR - SKIPPINIG\")\n",
    "\n",
    "def has_key(dict, key): \n",
    "    if key in dict.keys(): \n",
    "        return 1 \n",
    "    return 0\n",
    "\n",
    "labels = {} \n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = vec1.reshape(1, -1)\n",
    "    vec2 = vec2.reshape(1, -1)\n",
    "    return  cosine_similarity(vec1,vec2)[0][0]\n",
    "\n",
    "def similarity(a, b):\n",
    "    words_in_a = a.replace(',', ' ').split()\n",
    "    words_in_b = b.replace(',', ' ').split()\n",
    "    if(len(words_in_a) ==  1 and words_in_a[0] in words_in_b):\n",
    "        return 1\n",
    "    if(len(words_in_b) ==  1 and words_in_b[0] in words_in_a):\n",
    "        return -1\n",
    "    \n",
    "    total_ratio = 0\n",
    "    for word_a in words_in_a:\n",
    "        a_ratio = 0\n",
    "        for word_b in words_in_b:\n",
    "            b_ratio = SequenceMatcher(None, a, b).ratio()\n",
    "            if(b_ratio > a_ratio):\n",
    "                a_ratio = b_ratio\n",
    "        total_ratio += a_ratio\n",
    "    \n",
    "    return total_ratio / len(words_in_a)\n",
    "\n",
    "def readLabels(jsonData): \n",
    "    key = jsonData[\"Suç\"].strip().lower() if jsonData[\"Suç\"] != '' else \"undefined\"\n",
    "    if (not has_key(labels, key)):\n",
    "        labels[key] = 1    \n",
    "    else :\n",
    "        labels[key] = labels[key] + 1\n",
    "\n",
    "for file in json_arr: \n",
    "    readLabels(file)\n",
    "\n",
    "items = list(map(lambda x: list(x), labels.items()))\n",
    "labels_array = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "vectorize_array = list(map(lambda x: x[0], labels_array))\n",
    "vectorizer = CountVectorizer().fit_transform(vectorize_array)\n",
    "vectors = vectorizer.toarray()\n",
    "\n",
    "len_labels_array = len(labels_array)\n",
    "for i in range(0, len_labels_array):\n",
    "    \n",
    "    for j in range(i, len_labels_array):\n",
    "        if labels_array[i][0] == labels_array[j][0] or labels_array[i][1] <= 1 or labels_array[j][1] <= 1 :\n",
    "            continue\n",
    "        \n",
    "        i_search = re.search('([0-9].*) sayılı', labels_array[i][0])\n",
    "        j_search = re.search('([0-9].*) sayılı', labels_array[j][0])\n",
    "        if(j_search != None and i_search != None):\n",
    "            if(i_search[0] == j_search[0]):\n",
    "                labels_array[i][1] += labels_array[j][1]\n",
    "                labels_array[j][1] = 0\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        cos_similarity = cosine_sim(vectors[i], vectors[j])\n",
    "        if cos_similarity > similarity_ratio:\n",
    "            labels_array[i][1] += labels_array[j][1]\n",
    "            labels_array[j][1] = 0\n",
    "            continue\n",
    "        \n",
    "        similarity_result = similarity(labels_array[i][0], labels_array[j][0])\n",
    "        if similarity_result == -1:\n",
    "            labels_array[j][1] += labels_array[i][1]\n",
    "            labels_array[i][1] = 0\n",
    "        elif similarity_result > similarity_ratio:\n",
    "            labels_array[i][1] += labels_array[j][1]\n",
    "            labels_array[j][1] = 0\n",
    "\n",
    "\n",
    "\n",
    "array_final = (list(filter(lambda x: x[1] > 1 , labels_array)))\n",
    "\n",
    "    \n",
    "array_final = sorted(array_final, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    \n",
    "jsonString = json.dumps(array_final, indent = 4, ensure_ascii=False)\n",
    "jsonFile = open(\"data.json\", \"w\", encoding='utf-8')\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da360665-ec6b-4c02-910d-fef63c8028d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "04b5d09b-1eeb-4c9d-b8e4-c75ce6dd9296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if(not enable_preprocessing):\n",
    "    raise Exception(\"NOT ERROR - SKIPPINIG\")\n",
    "    \n",
    "ictihats = []\n",
    "suc_array = []\n",
    "\n",
    "def similar(a, topTenCrimes):\n",
    "    for crime in topTenCrimes:\n",
    "        if SequenceMatcher(None, a, crime).ratio() > similarity_ratio:\n",
    "            return crime\n",
    "    return None\n",
    "                \n",
    "top_ten_crimes = []\n",
    "with open(\"data.json\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    top_ten_crimes = list(map(lambda x: x[0], data[:10]))\n",
    "\n",
    "\n",
    "\n",
    "for jsonData in json_arr:\n",
    "    key = jsonData[\"Suç\"] if jsonData[\"Suç\"] != '' else \"undefined\"\n",
    "    similar_suc = similar(key, top_ten_crimes)\n",
    "    \n",
    "    key = similar_suc if similar_suc is not None else key\n",
    "    suc = key if key in top_ten_crimes or key == 'undefined' else \"other\"\n",
    "\n",
    "    new_ictihat = jsonData['ictihat'].strip()\n",
    "    ictihats.append(new_ictihat)\n",
    "    new_ictihat_ctr = new_ictihat.split()\n",
    "    num_of_words = len(new_ictihat_ctr)\n",
    "    suc_array.append(suc.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f9426-0989-4e9c-86ca-9761ae0c9fe5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "72cb2224-5f34-4e3b-a69c-e7dd2d206800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if(not enable_preprocessing):\n",
    "    raise Exception(\"NOT ERROR - SKIPPINIG\")\n",
    "\n",
    "ictihats_lower = []\n",
    "for i in ictihats:\n",
    "    i = i.lower()\n",
    "    ictihats_lower.append(i)\n",
    "    \n",
    "\n",
    "ictihats_punctuation = []\n",
    "\n",
    "file = open(\"stopwords.txt\", \"r\", newline='', encoding='utf-8')\n",
    "result = file.read()\n",
    "stopwords = word_tokenize(result)\n",
    "\n",
    "for ictihat in ictihats_lower:\n",
    "    ictihat = ictihat.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    #print(ictihat)\n",
    "    tokenized_words = ([word for word in ictihat.split() if word not in stopwords and len(word) > 1 and re.match(\"^[A-Z0-9a-zğüşöçİĞÜŞÖÇ]*$\", word)])\n",
    "    #print(tokenized_words)\n",
    "    ictihats_punctuation.append(' '.join(tokenized_words[:word_size_threshold]))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# print(ictihats_punctuation[:10])   \n",
    "# preprocessed_ictihats = []\n",
    "# for i in ictihats_punctuation:\n",
    "#     preprocessed_ictihats.append(list(filter(lambda x: x != \"\",i.split(\" \"))))\n",
    "\n",
    "# print(preprocessed_ictihats)\n",
    "turkStem = TurkishStemmer()\n",
    "for index, ictihat in enumerate(ictihats_punctuation,start=0):\n",
    "    #print([turkStem.stemWord(word) for word in ictihat])\n",
    "    ictihats_punctuation[index] = ' '.join([turkStem.stemWord(word) for word in ictihat.split()])\n",
    "    \n",
    "#print(ictihats_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945fcd6-9d25-4146-8d98-cb76b1c130bd",
   "metadata": {},
   "source": [
    "## write data into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e54c0132-3234-404c-a793-21b194fb1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not enable_preprocessing):\n",
    "    raise Exception(\"NOT ERROR - SKIPPINIG\")\n",
    "\n",
    "df = pd.DataFrame(columns = ['ictihats', 'sucs'])\n",
    "df['ictihats'] = ictihats_punctuation\n",
    "df['sucs'] = suc_array\n",
    "csv_file_name = 'train_set_' + str(word_size_threshold) + '.csv'\n",
    "\n",
    "df.to_csv(csv_file_name, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93ae09-56b7-48a3-9ea3-82af883c29ea",
   "metadata": {},
   "source": [
    "## Read train set from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "57b92992-6042-48bb-94f3-b3b38296e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = 'train_set_' + str(word_size_threshold) + '.csv'\n",
    "my_csv = pd.read_csv(csv_file_name, dtype=str, na_filter=False)\n",
    "ictihats_punctuation = my_csv['ictihats'].tolist()\n",
    "suc_array = my_csv['sucs'].tolist()\n",
    "\n",
    "for item in ictihats_punctuation:\n",
    "    if(type(item).__name__ != \"str\"):\n",
    "        print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511863a-1224-49c8-ad2b-a47cad91a28d",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a780d958-a973-486e-8e1f-c32564ee22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(ictihats_punctuation, \n",
    "                                                    suc_array, \n",
    "                                                    test_size=0.20,random_state=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb6583-90bb-4d17-8ad7-54fbd86347a6",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b320805f-a5fb-4ff1-8d23-5fb0cb168dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "training_data = tfidfvectorizer.fit_transform(x_train)\n",
    "testing_data = tfidfvectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbeb31-1cb7-4469-907e-e91da1c6cfba",
   "metadata": {},
   "source": [
    "## Support Vector Machines (specifically linear SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8a69dc08-6bf8-49ed-998f-702fb4805b35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 147    0    0    0    0    0   10    1    0    1    0]\n",
      " [   0   34    0    0    0    0   18    0    0    1    0]\n",
      " [   0    0   64    0    0    0   19    0    6    0    0]\n",
      " [   0    1    0   78    0    0   67    1    0    0    0]\n",
      " [   0    0    2    0  374    0   19    0    2    0    0]\n",
      " [   0    0    0    0    0   60    4    0    0    0    3]\n",
      " [  32    4    9   26   31    1 1622    5   12    5   15]\n",
      " [   0    0    0    0    0    0   22   23    0    0    0]\n",
      " [   0    0    7    0    0    0   48    0   48    0    0]\n",
      " [   0    2    0    1    6    1   21    1    0 2580    2]\n",
      " [   0    0    0    0    0    2    0    0    0    0  133]]\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "              5607 sayılı kanuna muhalefet       0.82      0.92      0.87       159\n",
      "                            dolandırıcılık       0.83      0.64      0.72        53\n",
      "                                   hakaret       0.78      0.72      0.75        89\n",
      "                                 hırsızlık       0.74      0.53      0.62       147\n",
      "                           kasten yaralama       0.91      0.94      0.93       397\n",
      "kullanmak için uyuşturucu madde bulundurma       0.94      0.90      0.92        67\n",
      "                                     other       0.88      0.92      0.90      1762\n",
      "                  resmi belgede sahtecilik       0.74      0.51      0.61        45\n",
      "                                    tehdit       0.71      0.47      0.56       103\n",
      "                                 undefined       1.00      0.99      0.99      2614\n",
      "           uyuşturucu madde ticareti yapma       0.87      0.99      0.92       135\n",
      "\n",
      "                                  accuracy                           0.93      5571\n",
      "                                 macro avg       0.84      0.77      0.80      5571\n",
      "                              weighted avg       0.92      0.93      0.92      5571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(training_data, y_train)\n",
    "y_pred = svclassifier.predict(testing_data)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8458b-83e9-4373-8b27-cb610f2106d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c5c756d9-52e6-430d-be96-e8324245522a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   9    0    0    0    0    0  149    0    0    1    0]\n",
      " [   0    0    0    0    0    0   50    0    0    3    0]\n",
      " [   0    0    0    0    0    0   89    0    0    0    0]\n",
      " [   0    0    0    0    0    0  144    0    0    3    0]\n",
      " [   0    0    0    0   84    0  305    0    0    8    0]\n",
      " [   0    0    0    0    0    0   49    0    0   18    0]\n",
      " [   3    0    0    0    0    0 1710    0    0   49    0]\n",
      " [   0    0    0    0    0    0   41    0    0    4    0]\n",
      " [   0    0    0    0    0    0  102    0    0    1    0]\n",
      " [   1    0    0    0    2    0  237    0    0 2374    0]\n",
      " [   0    0    0    0    0    0   89    0    0   46    0]]\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "              5607 sayılı kanuna muhalefet       0.69      0.06      0.10       159\n",
      "                            dolandırıcılık       0.00      0.00      0.00        53\n",
      "                                   hakaret       0.00      0.00      0.00        89\n",
      "                                 hırsızlık       0.00      0.00      0.00       147\n",
      "                           kasten yaralama       0.98      0.21      0.35       397\n",
      "kullanmak için uyuşturucu madde bulundurma       0.00      0.00      0.00        67\n",
      "                                     other       0.58      0.97      0.72      1762\n",
      "                  resmi belgede sahtecilik       0.00      0.00      0.00        45\n",
      "                                    tehdit       0.00      0.00      0.00       103\n",
      "                                 undefined       0.95      0.91      0.93      2614\n",
      "           uyuşturucu madde ticareti yapma       0.00      0.00      0.00       135\n",
      "\n",
      "                                  accuracy                           0.75      5571\n",
      "                                 macro avg       0.29      0.20      0.19      5571\n",
      "                              weighted avg       0.72      0.75      0.69      5571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anlsn\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\anlsn\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\anlsn\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "predictions = naive_bayes.predict(testing_data)\n",
    "\n",
    "# print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "# print('Precision score: ', format(precision_score(y_test, predictions, average='weighted')))\n",
    "# print('Recall score: ', format(recall_score(y_test, predictions ,average='weighted')))\n",
    "# print('F1 score: ', format(f1_score(y_test, predictions ,average='weighted')))\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707aeff-312d-4036-8c95-f46f880a4c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3637a68f-37f8-41b9-9c6e-3fc371d40ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anlsn\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 141    0    0    0    0    0   14    0    0    4    0]\n",
      " [   0   30    0    0    0    0   20    0    0    3    0]\n",
      " [   0    0   45    0    0    0   39    0    5    0    0]\n",
      " [   0    0    0   67    0    0   78    0    0    2    0]\n",
      " [   0    0    2    0  364    0   26    0    2    3    0]\n",
      " [   0    0    0    0    0   54    5    0    0    3    5]\n",
      " [  30    2    6   18   29    1 1637    4    6   15   14]\n",
      " [   0    0    0    0    0    0   28   16    0    1    0]\n",
      " [   0    0    7    0    0    0   51    0   45    0    0]\n",
      " [   0    1    0    1    6    1   40    1    0 2561    3]\n",
      " [   0    0    0    0    0    2    3    0    0    0  130]]\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "              5607 sayılı kanuna muhalefet       0.82      0.89      0.85       159\n",
      "                            dolandırıcılık       0.91      0.57      0.70        53\n",
      "                                   hakaret       0.75      0.51      0.60        89\n",
      "                                 hırsızlık       0.78      0.46      0.58       147\n",
      "                           kasten yaralama       0.91      0.92      0.91       397\n",
      "kullanmak için uyuşturucu madde bulundurma       0.93      0.81      0.86        67\n",
      "                                     other       0.84      0.93      0.88      1762\n",
      "                  resmi belgede sahtecilik       0.76      0.36      0.48        45\n",
      "                                    tehdit       0.78      0.44      0.56       103\n",
      "                                 undefined       0.99      0.98      0.98      2614\n",
      "           uyuşturucu madde ticareti yapma       0.86      0.96      0.91       135\n",
      "\n",
      "                                  accuracy                           0.91      5571\n",
      "                                 macro avg       0.85      0.71      0.76      5571\n",
      "                              weighted avg       0.91      0.91      0.91      5571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_regres_classifier = LogisticRegression(random_state = 36)\n",
    "log_regres_classifier.fit(training_data, y_train)\n",
    "y_pred = log_regres_classifier.predict(testing_data)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# print('Accuracy score: ', (accuracy_score(y_test, y_pred)))\n",
    "# print('Precision score: ', (precision_score(y_test, y_pred, average='weighted')))\n",
    "# print('Recall score: ', (recall_score(y_test, y_pred ,average='weighted')))\n",
    "# print('F1 score: ', (f1_score(y_test, y_pred ,average='weighted')))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d31b01-d80b-4e39-806f-8cc51b675ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd4f5c30-bf9c-4386-b1fc-1554137eb9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(len(suc_array))\n",
    "#print(ictihats_punctuation)\n",
    "# index_list = []\n",
    "# for i in range(0,100):\n",
    "#     index_list.append(str(i))\n",
    "\n",
    "# preprocessed_ictihats = []\n",
    "# for i in ictihats_punctuation:\n",
    "#        preprocessed_ictihats.append(list(filter(lambda x: x != \"\",i.split(\" \"))))\n",
    "\n",
    "# #print(preprocessed_ictihats)\n",
    "# turkStem = TurkishStemmer()\n",
    "# for index, ictihat in enumerate(preprocessed_ictihats,start=0):\n",
    "#     preprocessed_ictihats[index] = [turkStem.stemWord(word) for word in ictihat]\n",
    "    \n",
    "#print(preprocessed_ictihats)\n",
    "\n",
    "#tfidf_wm_array\n",
    "#tfidf_wm_array.shape\n",
    "# frequency_matrix = pd.DataFrame(tfidf_wm_array, columns=tfidfvectorizer.get_feature_names())\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# y = np.array([0,1,2,3,4,5,6,7,8,9,10]) \n",
    "\n",
    "\n",
    "# naive_bayes = MultinomialNB()\n",
    "# naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "# predictions = naive_bayes.predict(testing_data)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "# print('Precision score: ', format(precision_score(y_test, predictions,\n",
    "#                                            average='macro')))\n",
    "# print('Recall score: ', format(recall_score(y_test, predictions\n",
    "#                                            ,average='macro')))\n",
    "# print('F1 score: ', format(f1_score(y_test, predictions\n",
    "#                                            ,average='macro')))\n",
    "\n",
    "# print(confusion_matrix(y_test,predictions))\n",
    "\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# svclassifier = SVC(kernel='linear')\n",
    "# svclassifier.fit(training_data, y_train)\n",
    "# y_pred = svclassifier.predict(testing_data)\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# print(confusion_matrix(y_test,y_pred))\n",
    "# print(classification_report(y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# frequency_matrix\n",
    "# print(tfidfvectorizer.vocabulary_)\n",
    "# print(tfidf_wm.toarray())\n",
    "# tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "# df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = index_list,columns = tfidf_tokens)\n",
    "# print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "# print(df_tfidfvect)\n",
    "# vectorizer.get_feature_names_out()\n",
    "# ictihat_freq = []\n",
    "\n",
    "\n",
    "# for i in preprocessed_ictihats:\n",
    "#     count_freq = Counter(i)\n",
    "#     ictihat_freq.append(count_freq)\n",
    "    \n",
    "# pprint.pprint(ictihat_freq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ce705-6e4d-44f0-95d6-ff6a5d0322ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
