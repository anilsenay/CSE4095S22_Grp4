{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cb0d22-f68c-4d89-9426-0cb0ef5ad86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,re, os, glob, json, string, pprint\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from snowballstemmer import TurkishStemmer \n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "word_size_threshold = 100\n",
    "similarity_ratio = 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da360665-ec6b-4c02-910d-fef63c8028d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b5d09b-1eeb-4c9d-b8e4-c75ce6dd9296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# similar(' 5607 sayılı Kanuna Aykırılık',' 5607 sayılı Kanuna Aykırılık')\n",
    "\n",
    "\n",
    "\n",
    "path = \"C://Users/onkol/Desktop/2021-01-20220322T055600Z-001/2021-01/*.json\" \n",
    "files = glob.glob(path)\n",
    "\n",
    "ictihats = []\n",
    "suc_array = []\n",
    "\n",
    "def similar(a, topTenCrimes):\n",
    "    for crime in topTenCrimes:\n",
    "        if SequenceMatcher(None, a, crime).ratio() > similarity_ratio:\n",
    "            return crime\n",
    "    return None\n",
    "                \n",
    "top_ten_crimes = []\n",
    "with open(\"data.json\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    top_ten_crimes = list(map(lambda x: x[0], data[:10]))\n",
    "\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    f = open(file, \"r\", encoding='utf-8')\n",
    "    jsonData = json.loads(f.read())\n",
    "    key = jsonData[\"Suç\"] if jsonData[\"Suç\"] != '' else \"undefined\"\n",
    "    similar_suc = similar(key, top_ten_crimes)\n",
    "    \n",
    "    key = similar_suc if similar_suc is not None else key\n",
    "    suc = key if key in top_ten_crimes or key == 'undefined' else \"other\"\n",
    "\n",
    "    new_ictihat = jsonData['ictihat'].strip()\n",
    "    ictihats.append(new_ictihat)\n",
    "    new_ictihat_ctr = new_ictihat.split()\n",
    "    num_of_words = len(new_ictihat_ctr)\n",
    "    suc_array.append(suc.strip())\n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59b8de-799b-4a9e-9843-d37938bf183d",
   "metadata": {},
   "source": [
    "## Create labels from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8988295e-bd09-43d4-ac70-ce241b775dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def has_key(dict, key): \n",
    "#     if key in dict.keys(): \n",
    "#         return 1 \n",
    "#     return 0\n",
    "\n",
    "# labels = {} \n",
    "\n",
    "# def similarity(a, b):\n",
    "#     return SequenceMatcher(None, a, b).ratio()\n",
    "    \n",
    "# #similarity(' 5607 sayılı Kanuna muhalefet', ' 5607 Sayılı Kanuna Aykırılık' )\n",
    "# def readLabels(fileName): \n",
    "#     f = open(file, \"r\", encoding='utf-8') \n",
    "#     jsonData = json.loads(f.read())\n",
    "#     key = jsonData[\"Suç\"] if jsonData[\"Suç\"] != '' else \"undefined\"\n",
    "#     if (not has_key(labels, key)):\n",
    "#         labels[key] = 1    \n",
    "#     else :\n",
    "#         labels[key] = labels[key] + 1\n",
    "\n",
    "# path = \"C://Users/onkol/Desktop/2021-01-20220322T055600Z-001/2021-01/*.json\" \n",
    "# files = glob.glob(path)\n",
    "\n",
    "# for file in files: \n",
    "#     readLabels(file)\n",
    "\n",
    "\n",
    "# items = list(map(lambda x: list(x), labels.items()))\n",
    "# #print(type(items[0]))\n",
    "# labels_array = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# len_labels_array = len(labels_array)\n",
    "# for i in range(0, len_labels_array):\n",
    "    \n",
    "#     for j in range(i, len_labels_array):\n",
    "#         if labels_array[i][0] == labels_array[j][0] or labels_array[i][1] <= 1 or labels_array[j][1] <= 1 :\n",
    "#             continue\n",
    "#         if similarity(labels_array[i][0], labels_array[j][0]) > similarity_ratio:\n",
    "#             labels_array[i][1] += labels_array[j][1]\n",
    "#             labels_array[j][1] = 0\n",
    "\n",
    "# array_final = (list(filter(lambda x: x[1] > 1 , labels_array)))\n",
    "\n",
    "    \n",
    "# array_final = sorted(array_final, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    \n",
    "# jsonString = json.dumps(array_final, indent = 4, ensure_ascii=False)\n",
    "# jsonFile = open(\"data.json\", \"w\", encoding='utf-8')\n",
    "# jsonFile.write(jsonString)\n",
    "# jsonFile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f9426-0989-4e9c-86ca-9761ae0c9fe5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72cb2224-5f34-4e3b-a69c-e7dd2d206800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ictihats_lower = []\n",
    "for i in ictihats:\n",
    "    i = i.lower()\n",
    "    ictihats_lower.append(i)\n",
    "    \n",
    "\n",
    "ictihats_punctuation = []\n",
    "\n",
    "file = open(\"stopwords.txt\", \"r\", newline='', encoding='utf-8')\n",
    "result = file.read()\n",
    "stopwords = word_tokenize(result)\n",
    "\n",
    "for ictihat in ictihats_lower:\n",
    "    ictihat = ictihat.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    #print(ictihat)\n",
    "    tokenized_words = ([word for word in ictihat.split() if word not in stopwords and len(word) > 1 and re.match(\"^[A-Z0-9a-zğüşöçİĞÜŞÖÇ]*$\", word)])\n",
    "    #print(tokenized_words)\n",
    "    ictihats_punctuation.append(' '.join(tokenized_words[:word_size_threshold]))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# print(ictihats_punctuation[:10])   \n",
    "# preprocessed_ictihats = []\n",
    "# for i in ictihats_punctuation:\n",
    "#     preprocessed_ictihats.append(list(filter(lambda x: x != \"\",i.split(\" \"))))\n",
    "\n",
    "# print(preprocessed_ictihats)\n",
    "turkStem = TurkishStemmer()\n",
    "for index, ictihat in enumerate(ictihats_punctuation,start=0):\n",
    "    #print([turkStem.stemWord(word) for word in ictihat])\n",
    "    ictihats_punctuation[index] = ' '.join([turkStem.stemWord(word) for word in ictihat.split()])\n",
    "    \n",
    "#print(ictihats_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945fcd6-9d25-4146-8d98-cb76b1c130bd",
   "metadata": {},
   "source": [
    "## write data into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54c0132-3234-404c-a793-21b194fb1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['ictihats', 'sucs'])\n",
    "df['ictihats'] = ictihats_punctuation\n",
    "df['sucs'] = suc_array\n",
    "csv_file_name = 'train_set_' + str(word_size_threshold) + '.csv'\n",
    "\n",
    "df.to_csv(csv_file_name, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511863a-1224-49c8-ad2b-a47cad91a28d",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a780d958-a973-486e-8e1f-c32564ee22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_csv = pd.read_csv(filename)\n",
    "# column = csv_file_name[]\n",
    "# csv_file_name = 'train_set_' + str(word_size_threshold) + '.csv'\n",
    "# my_csv = pd.read_csv(csv_file_name)\n",
    "# #print(my_csv.columns)\n",
    "# x = my_csv['ictihats']\n",
    "# print(x.tolist())\n",
    "# y = my_csv['sucs']\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=36)\n",
    "#print(x_train)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(ictihats_punctuation, \n",
    "                                                    suc_array, \n",
    "                                                    test_size=0.20,random_state=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb6583-90bb-4d17-8ad7-54fbd86347a6",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b320805f-a5fb-4ff1-8d23-5fb0cb168dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "training_data = tfidfvectorizer.fit_transform(x_train)\n",
    "testing_data = tfidfvectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbeb31-1cb7-4469-907e-e91da1c6cfba",
   "metadata": {},
   "source": [
    "## Support Vector Machines (specifically linear SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a69dc08-6bf8-49ed-998f-702fb4805b35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 238    1    0    0    0    0    5    0    0   12    0]\n",
      " [  37   15    0    0    0    0    3    0    0   49    0]\n",
      " [   0    0   65    0    0    0    0    8    0   30    0]\n",
      " [   0    0    1   88    7    1    0    0    0   54    0]\n",
      " [   0    0    0   24   36    0    1    0    0   26    0]\n",
      " [   0    0    0   12    4   19    1    0    0   38    0]\n",
      " [   0    1    1    3    0    2  399    2    0   37    0]\n",
      " [   0    0    8    0    0    0    0   55    0   40    0]\n",
      " [   0    0    0    0    0    0    0    0  138    5    0]\n",
      " [   2    5   12   16    6    8   26   10   12 1391    3]\n",
      " [   2    2    0    0    0    0    3    0    2   16 2589]]\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "           5607 sayılı Kanuna muhalefet       0.85      0.93      0.89       256\n",
      "           6136 sayılı Yasaya aykırılık       0.62      0.14      0.23       104\n",
      "                                Hakaret       0.75      0.63      0.68       103\n",
      "                              Hırsızlık       0.62      0.58      0.60       151\n",
      "Hırsızlık, konut dokunulmazlığını bozma       0.68      0.41      0.51        87\n",
      "                Kamu malına zarar verme       0.63      0.26      0.37        74\n",
      "                        Kasten yaralama       0.91      0.90      0.90       445\n",
      "                                 Tehdit       0.73      0.53      0.62       103\n",
      "        Uyuşturucu madde ticareti yapma       0.91      0.97      0.94       143\n",
      "                                  other       0.82      0.93      0.87      1491\n",
      "                              undefined       1.00      0.99      0.99      2614\n",
      "\n",
      "                               accuracy                           0.90      5571\n",
      "                              macro avg       0.77      0.66      0.69      5571\n",
      "                           weighted avg       0.90      0.90      0.89      5571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(training_data, y_train)\n",
    "y_pred = svclassifier.predict(testing_data)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8458b-83e9-4373-8b27-cb610f2106d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5c756d9-52e6-430d-be96-e8324245522a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 118    0    0    0    0    0    0    0    0  131    7]\n",
      " [  22    0    0    0    0    0    1    0    0   77    4]\n",
      " [   0    0    0    0    0    0    0    0    0  102    1]\n",
      " [   0    0    0    0    0    0    0    0    0  144    7]\n",
      " [   0    0    0    0    0    0    0    0    0   82    5]\n",
      " [   0    0    0    0    0    0    2    0    0   68    4]\n",
      " [   0    0    0    0    0    0  218    0    0  205   22]\n",
      " [   0    0    0    0    0    0    0    0    0  103    0]\n",
      " [   0    0    0    0    0    0    0    0    1   79   63]\n",
      " [   0    0    0    0    0    0    6    0    0 1446   39]\n",
      " [   3    0    0    0    0    0    7    0    0  155 2449]]\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "           5607 sayılı Kanuna muhalefet       0.83      0.46      0.59       256\n",
      "           6136 sayılı Yasaya aykırılık       0.00      0.00      0.00       104\n",
      "                                Hakaret       0.00      0.00      0.00       103\n",
      "                              Hırsızlık       0.00      0.00      0.00       151\n",
      "Hırsızlık, konut dokunulmazlığını bozma       0.00      0.00      0.00        87\n",
      "                Kamu malına zarar verme       0.00      0.00      0.00        74\n",
      "                        Kasten yaralama       0.93      0.49      0.64       445\n",
      "                                 Tehdit       0.00      0.00      0.00       103\n",
      "        Uyuşturucu madde ticareti yapma       1.00      0.01      0.01       143\n",
      "                                  other       0.56      0.97      0.71      1491\n",
      "                              undefined       0.94      0.94      0.94      2614\n",
      "\n",
      "                               accuracy                           0.76      5571\n",
      "                              macro avg       0.39      0.26      0.26      5571\n",
      "                           weighted avg       0.73      0.76      0.71      5571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onkol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\onkol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\onkol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "predictions = naive_bayes.predict(testing_data)\n",
    "\n",
    "# print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "# print('Precision score: ', format(precision_score(y_test, predictions, average='weighted')))\n",
    "# print('Recall score: ', format(recall_score(y_test, predictions ,average='weighted')))\n",
    "# print('F1 score: ', format(f1_score(y_test, predictions ,average='weighted')))\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707aeff-312d-4036-8c95-f46f880a4c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3637a68f-37f8-41b9-9c6e-3fc371d40ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onkol\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 231    1    0    0    0    0    6    0    0   17    1]\n",
      " [  34   16    0    0    0    0    3    0    0   51    0]\n",
      " [   0    0   58    0    0    0    0    8    0   37    0]\n",
      " [   0    0    0   80    8    0    0    0    0   62    1]\n",
      " [   0    0    0   23   34    2    1    0    0   25    2]\n",
      " [   0    0    0    7    3   14    1    0    0   49    0]\n",
      " [   0    0    2    2    0    0  397    2    0   41    1]\n",
      " [   0    0    8    0    0    0    0   49    0   45    1]\n",
      " [   0    0    0    0    0    0    0    0  137    6    0]\n",
      " [   4    3   11   13    7    8   26   10   12 1389    8]\n",
      " [   2    1    0    1    0    2    4    0    0   22 2582]]\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "           5607 sayılı Kanuna muhalefet       0.85      0.90      0.88       256\n",
      "           6136 sayılı Yasaya aykırılık       0.76      0.15      0.26       104\n",
      "                                Hakaret       0.73      0.56      0.64       103\n",
      "                              Hırsızlık       0.63      0.53      0.58       151\n",
      "Hırsızlık, konut dokunulmazlığını bozma       0.65      0.39      0.49        87\n",
      "                Kamu malına zarar verme       0.54      0.19      0.28        74\n",
      "                        Kasten yaralama       0.91      0.89      0.90       445\n",
      "                                 Tehdit       0.71      0.48      0.57       103\n",
      "        Uyuşturucu madde ticareti yapma       0.92      0.96      0.94       143\n",
      "                                  other       0.80      0.93      0.86      1491\n",
      "                              undefined       0.99      0.99      0.99      2614\n",
      "\n",
      "                               accuracy                           0.90      5571\n",
      "                              macro avg       0.77      0.63      0.67      5571\n",
      "                           weighted avg       0.89      0.90      0.89      5571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_regres_classifier = LogisticRegression(random_state = 36)\n",
    "log_regres_classifier.fit(training_data, y_train)\n",
    "y_pred = log_regres_classifier.predict(testing_data)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# print('Accuracy score: ', (accuracy_score(y_test, y_pred)))\n",
    "# print('Precision score: ', (precision_score(y_test, y_pred, average='weighted')))\n",
    "# print('Recall score: ', (recall_score(y_test, y_pred ,average='weighted')))\n",
    "# print('F1 score: ', (f1_score(y_test, y_pred ,average='weighted')))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd4f5c30-bf9c-4386-b1fc-1554137eb9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(len(suc_array))\n",
    "#print(ictihats_punctuation)\n",
    "# index_list = []\n",
    "# for i in range(0,100):\n",
    "#     index_list.append(str(i))\n",
    "\n",
    "# preprocessed_ictihats = []\n",
    "# for i in ictihats_punctuation:\n",
    "#        preprocessed_ictihats.append(list(filter(lambda x: x != \"\",i.split(\" \"))))\n",
    "\n",
    "# #print(preprocessed_ictihats)\n",
    "# turkStem = TurkishStemmer()\n",
    "# for index, ictihat in enumerate(preprocessed_ictihats,start=0):\n",
    "#     preprocessed_ictihats[index] = [turkStem.stemWord(word) for word in ictihat]\n",
    "    \n",
    "#print(preprocessed_ictihats)\n",
    "\n",
    "#tfidf_wm_array\n",
    "#tfidf_wm_array.shape\n",
    "# frequency_matrix = pd.DataFrame(tfidf_wm_array, columns=tfidfvectorizer.get_feature_names())\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# y = np.array([0,1,2,3,4,5,6,7,8,9,10]) \n",
    "\n",
    "\n",
    "# naive_bayes = MultinomialNB()\n",
    "# naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "# predictions = naive_bayes.predict(testing_data)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "# print('Precision score: ', format(precision_score(y_test, predictions,\n",
    "#                                            average='macro')))\n",
    "# print('Recall score: ', format(recall_score(y_test, predictions\n",
    "#                                            ,average='macro')))\n",
    "# print('F1 score: ', format(f1_score(y_test, predictions\n",
    "#                                            ,average='macro')))\n",
    "\n",
    "# print(confusion_matrix(y_test,predictions))\n",
    "\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# svclassifier = SVC(kernel='linear')\n",
    "# svclassifier.fit(training_data, y_train)\n",
    "# y_pred = svclassifier.predict(testing_data)\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# print(confusion_matrix(y_test,y_pred))\n",
    "# print(classification_report(y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# frequency_matrix\n",
    "# print(tfidfvectorizer.vocabulary_)\n",
    "# print(tfidf_wm.toarray())\n",
    "# tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "# df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = index_list,columns = tfidf_tokens)\n",
    "# print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "# print(df_tfidfvect)\n",
    "# vectorizer.get_feature_names_out()\n",
    "# ictihat_freq = []\n",
    "\n",
    "\n",
    "# for i in preprocessed_ictihats:\n",
    "#     count_freq = Counter(i)\n",
    "#     ictihat_freq.append(count_freq)\n",
    "    \n",
    "# pprint.pprint(ictihat_freq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ce705-6e4d-44f0-95d6-ff6a5d0322ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
